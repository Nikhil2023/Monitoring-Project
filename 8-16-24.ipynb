{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3849d39e-c804-458f-99ae-9a646a271a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Fetch the data from the URL\n",
    "url = 'https://raw.githubusercontent.com/Nikhil2023/Monitoring-Project/main/Data_Anonymized.csv'\n",
    "headers = {'Authorization': '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u'}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Load the anonymized data into a DataFrame\n",
    "data_anonymized = pd.read_csv(StringIO(response.text))\n",
    "data_anonymized['endDate'] = pd.to_datetime(data_anonymized['endDate'])\n",
    "\n",
    "# Load the Excel file directly from GitHub into a DataFrame\n",
    "excel_url = 'https://github.com/Nikhil2023/Monitoring-Project/raw/main/Projects_Data.xlsx'\n",
    "projects_data = pd.read_excel(excel_url)\n",
    "\n",
    "# Ensure the Date column is in datetime format\n",
    "projects_data['Date'] = pd.to_datetime(projects_data['Date'])\n",
    "\n",
    "# Sort the anonymized data by propertyId and accountId_anonymized\n",
    "data_anonymized_sorted = data_anonymized.sort_values(by=['propertyId', 'accountId_anonymized'])\n",
    "\n",
    "# Get the Property ID from user input and convert it to an integer\n",
    "property_id_input = int(input(\"Property_Id: \"))\n",
    "\n",
    "# Filter by the inputted propertyId\n",
    "data_property_id_2 = data_anonymized_sorted[data_anonymized_sorted['propertyId'] == property_id_input]\n",
    "\n",
    "# Check if the filtered data is empty\n",
    "if not data_property_id_2.empty:\n",
    "    # Add new columns for project_1 and project_2\n",
    "    data_property_id_2['project_1'] = 0\n",
    "    data_property_id_2['project_2'] = 0\n",
    "\n",
    "    # Group project dates by propertyId\n",
    "    project_dates_by_property = projects_data.groupby('propertyId').apply(lambda x: dict(zip(x['projectId'], x['Date']))).to_dict()\n",
    "\n",
    "    # Update project columns based on date\n",
    "    for property_id, project_dates in project_dates_by_property.items():\n",
    "        for i, row in data_property_id_2.iterrows():\n",
    "            if row['propertyId'] == property_id:\n",
    "                for project_id, project_date in project_dates.items():\n",
    "                    if row['endDate'] >= project_date:\n",
    "                        data_property_id_2.at[i, f'project_{project_id}'] = 1\n",
    "                    else:\n",
    "                        data_property_id_2.at[i, f'project_{project_id}'] = 0\n",
    "\n",
    "    # Loop through each accountId_anonymized and perform regression\n",
    "    unique_accounts = data_property_id_2['accountId_anonymized'].unique()\n",
    "\n",
    "    for account_id in unique_accounts:\n",
    "        # Filter the data for the current accountId_anonymized\n",
    "        account_data = data_property_id_2[data_property_id_2['accountId_anonymized'] == account_id]\n",
    "\n",
    "        # Select the relevant columns for modeling\n",
    "        filtered_data = account_data[['hdd', 'cdd', 'project_1', 'project_2', 'consumptionGj']].dropna()\n",
    "\n",
    "        if filtered_data.shape[0] > 0:  # Ensure there's enough data to train the model\n",
    "            X = filtered_data[['hdd', 'cdd', 'project_1', 'project_2']]\n",
    "            y = filtered_data['consumptionGj']\n",
    "\n",
    "            # Create train and test sets\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "            # Create a regression model\n",
    "            model = LinearRegression()\n",
    "\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Get the coefficients and intercept\n",
    "            coefficients = model.coef_\n",
    "            intercept = model.intercept_\n",
    "\n",
    "            # Print the results for the current accountId_anonymized\n",
    "            print(f'Account ID: {account_id}')\n",
    "            print(f'Coefficients for hdd, cdd, project_1, project_2: {coefficients}\\n')\n",
    "\n",
    "        else:\n",
    "            print(f'Account ID: {account_id} has insufficient data for regression.\\n')\n",
    "\n",
    "else:\n",
    "    print(f\"No data found for Property ID: {property_id_input}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c99e98-d914-4815-8b88-eab8c38762b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "git bas pull from the cloud and create new branch on this project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb23940-b306-4e92-b6de-0b0f8753a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
